{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# wikipedia hyperlink network visualization\n",
    "\n",
    "data: https://snap.stanford.edu/data/wiki-topcats.html\n",
    "\n",
    "source: Jure Leskovec, Stanford University\n",
    "\n",
    "> This is a web graph of Wikipedia hyperlinks collected in September 2011. The network was constructed by first taking the largest strongly connected component of Wikipedia, then restricting to pages in the top set of categories (those with at least 100 pages), and finally taking the largest strongly connected component of the restricted graph.\n",
    " \n",
    "The goal is to utilise __PySpark__ to handle the data and to visualize and understand the network\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## the data\n",
    "\n",
    "the data rests in 3 text files of each Â±40MB\n",
    "- categories\n",
    "    - a line looks like: Category:Category_name; (series of numbers)\n",
    "    - Category:Buprestoidea; 301 302 303\n",
    "    - the numbers presumably represent the pages in the category \n",
    "- page names\n",
    "    - a line looks like: number Page_name\n",
    "    - 0 Chiasmal syndrome\n",
    "    - this represents the mappin of number to name\n",
    "- reduced\n",
    "    - a line consists of 2 tab separated numbers\n",
    "    - 52\t401135\n",
    "    - the numbers presumably represent a hyperlink so __edges in the graph__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### setup\n",
    "\n",
    "- count number of pages ( lines of page doc)\n",
    "- show all page names in a category "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "#import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "    sc = SparkContext('local')\n",
    "except NameError:\n",
    "    sc = SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sc.textFile(\"../data/wiki-topcats-page-names.txt\")\n",
    "edges = sc.textFile(\"../data/wiki-topcats-reduced.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(names.count(),edges.count())"
   ]
  },
  {
   "source": [
    "### some helper methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameByNumber(num):\n",
    "    num_str = str(num)+' '\n",
    "    name_filter = names.filter(lambda x: num_str in x[:len(str(num))+1])\\\n",
    "        .map(lambda x: x[len(str(num))+1:])\n",
    "    name = name_filter.collect()\n",
    "    return name[0]\n",
    "    \n",
    "def getLinksByNumber(num):\n",
    "    num_str = str(num)+'\\t'\n",
    "    edge_filter = edges.filter(lambda x: num_str in x[:len(str(num))+1])\\\n",
    "        .map(lambda x: x[len(str(num))+1:])\n",
    "    links = edge_filter.collect()\n",
    "    return links\n",
    "def getNextNamesByNumber(num):\n",
    "    next_nums = getLinksByNumber(num)\n",
    "    names=[]\n",
    "    for n in next_nums:\n",
    "        names.append(getNameByNumber(n))\n",
    "    return names\n",
    "def hasLinks(num):\n",
    "    # check getAllPagesWithLinks list in stead of whole doc\n",
    "    num_str = str(num)+'\\t'\n",
    "    edge_filter = edges.filter(lambda x: num_str in x[:len(str(num))+1])\n",
    "    if(edge_filter.count()==0):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getAllPagesWithLinks():\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number = 8484\n",
    "print(getNameByNumber(number))\n",
    "if(hasLinks(number)):\n",
    "    print(getNextNamesByNumber(number))\n",
    "else:\n",
    "    print(\"no links\")"
   ]
  },
  {
   "source": [
    "## display small example network\n",
    "\n",
    "- start with a number\n",
    "- get links\n",
    "- draw edge from name to next names"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in = 62\n",
    "name_in = getNameByNumber(num_in)\n",
    "next_nums = getLinksByNumber(num_in)\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for num in next_nums:  \n",
    "    G.add_edge(name_in,getNameByNumber(num))\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(names.take(10))"
   ]
  },
  {
   "source": [
    "### create network matrix, visualize & check sparsity\n",
    "\n",
    "1791488 nodes\n",
    "\n",
    "2645248 edges\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "B = sp.lil_matrix((1791489,1791489),dtype=np.int8)\n",
    "\n",
    "sample =edges.take(10)\n",
    "s_edges= sc.parallelize(sample)\n",
    "\n",
    "split_edges= edges.map(lambda x: x.split('\\t')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for id,x in enumerate(split_edges):\n",
    "    B[int(x[0]),int(x[1])]=1\n",
    "    if(id%100000==0):\n",
    "        print(id)\n",
    "print('matrix loaded')"
   ]
  },
  {
   "source": [
    "plotting the matrix is a large and slow operation (+300MB)\n",
    "\n",
    "so the code is commented out and here is a picture representation\n",
    "\n",
    "<img src=\"matrix.png\" alt=\"alt text\" width=\"400\"/>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the matrix\n",
    "#fig = plt.spy(B,markersize=0.01,marker=\".\")\n",
    "#fig.figure.savefig('matrix.png',dpi=500)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}