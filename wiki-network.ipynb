{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# wikipedia hyperlink network visualization\n",
    "\n",
    "data: https://snap.stanford.edu/data/wiki-topcats.html\n",
    "\n",
    "source: Jure Leskovec, Stanford University\n",
    "\n",
    "> This is a web graph of Wikipedia hyperlinks collected in September 2011. The network was constructed by first taking the largest strongly connected component of Wikipedia, then restricting to pages in the top set of categories (those with at least 100 pages), and finally taking the largest strongly connected component of the restricted graph.\n",
    " \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## explore the data\n",
    "\n",
    "the data rests in 3 text files of each Â±40MB\n",
    "- categories\n",
    "    - a line looks like: Category:Category_name; (series of numbers)\n",
    "    - Category:Buprestoidea; 301 302 303\n",
    "    - the numbers presumably represent the pages in the category \n",
    "- page names\n",
    "    - a line looks like: number Page_name\n",
    "    - 0 Chiasmal syndrome\n",
    "    - this represents the mappin of number to name\n",
    "- reduced\n",
    "    - a line consists of 2 tab separated numbers\n",
    "    - 52\t401135\n",
    "    - the numbers presumably represent a hyperlink so __edges in the graph__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- use spark \n",
    "- load data\n",
    "- count number of pages ( lines of page doc)\n",
    "- show all page names in a category "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "    sc = SparkContext('local')\n",
    "except NameError:\n",
    "    sc = SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sc.textFile(\"../data/wiki-topcats-page-names.txt\")\n",
    "edges = sc.textFile(\"../data/wiki-topcats-reduced.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNameByNumber(num):\n",
    "    num_str = str(num)+' '\n",
    "    name_filter = names.filter(lambda x: num_str in x[:len(str(num))+1])\\\n",
    "        .map(lambda x: x[len(str(num))+1:])\n",
    "    name = name_filter.collect()\n",
    "    return name[0]\n",
    "    \n",
    "def getLinksByNumber(num):\n",
    "    num_str = str(num)+'\\t'\n",
    "    edge_filter = edges.filter(lambda x: num_str in x[:len(str(num))+1])\\\n",
    "        .map(lambda x: x[len(str(num))+1:])\n",
    "    links = edge_filter.collect()\n",
    "    return links\n",
    "def getNextNamesByNumber(num):\n",
    "    next_nums = getLinksByNumber(num)\n",
    "    names=[]\n",
    "    for n in next_nums:\n",
    "        names.append(getNameByNumber(n))\n",
    "    return names\n",
    "def hasLinks(num):\n",
    "    num_str = str(num)+'\\t'\n",
    "    edge_filter = edges.filter(lambda x: num_str in x[:len(str(num))+1])\n",
    "    if(edge_filter.count()==0):\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pinakion\nno links\n"
    }
   ],
   "source": [
    "number = 2\n",
    "print(getNameByNumber(number))\n",
    "if(hasLinks(number)):\n",
    "    print(getNextNamesByNumber(number))\n",
    "else:\n",
    "    print(\"no links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;0 Chiasmal syndrome&#39;, &#39;1 Kleroterion&#39;, &#39;2 Pinakion&#39;, &#39;3 LyndonHochschildSerre spectral sequence&#39;, &quot;4 Zariski&#39;s main theorem&quot;, &#39;5 FultonHansen connectedness theorem&#39;, &quot;6 Cayley&#39;s ruled cubic surface&quot;, &#39;7 Annulus theorem&#39;, &quot;8 Bing&#39;s recognition theorem&quot;, &#39;9 BochnerMartinelli formula&#39;]\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(names.take(10))\n",
    "#lineLengths = lines.map(lambda s: len(s))\n",
    "#totalLength = lineLengths.reduce(lambda a, b: a + b)\n",
    "\n",
    "#print(totalLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}